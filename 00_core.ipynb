{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> core routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export \n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms as T\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_audio\n",
    "We'll start with a basic utilty to read an audio file.  If it's not at the sample rate we want, we'll automatically resample it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def load_audio(\n",
    "    filename:str,     # name of file to load\n",
    "    sr=48000,         # sample rate in Hz\n",
    "    verbose=True,     # whether or not to print notices of resampling\n",
    "    normalize=False,  # Load to full dB range\n",
    "    )->torch.tensor:\n",
    "    \"this loads an audio file as a torch tensor\"\n",
    "    audio, in_sr = torchaudio.load(filename)\n",
    "    if in_sr != sr:\n",
    "        if verbose: print(f\"Resampling {filename} from {in_sr} Hz to {sr} Hz\",flush=True)\n",
    "        resample_tf = T.Resample(in_sr, sr)\n",
    "        audio = resample_tf(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the file in `examples/`, let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling examples/example.wav from 44100 Hz to 48000 Hz\n"
     ]
    }
   ],
   "source": [
    "audio = load_audio('examples/example.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = load_audio('examples/example.wav',verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_silence\n",
    "\n",
    "Sometimes we'll want to know if a file is \"silent\", i.e. if its contents are quieter than some threshold.  Here's one simple way to implement that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def audio_float_to_int(waveform):\n",
    "    \"converts torch float to numpy int16 (for playback in notebooks)\"\n",
    "    return np.clip( waveform.cpu().numpy()*32768 , -32768, 32768).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "int16\n"
     ]
    }
   ],
   "source": [
    "print(audio.dtype)\n",
    "print(audio_float_to_int(audio).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def is_silence(\n",
    "    audio,       # torch tensor of (multichannel) audio\n",
    "    thresh=-60,  # threshold in dB below which we declare to be silence\n",
    "    ):\n",
    "    \"checks if entire clip is 'silence' below some dB threshold\"\n",
    "    dBmax = 20*torch.log10(torch.flatten(audio.abs()).max()).cpu().numpy()\n",
    "    return dBmax < thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that with some tests.  If all goes well, the following `assert` statements will all pass uneventfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((2,10))\n",
    "assert not is_silence(1e-3*x) # not silent\n",
    "assert is_silence(1e-5*x) # silent\n",
    "assert is_silence(1e-3*x, thresh=-50) # higher thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch_it_crazy\n",
    "This is a pretty basic utility for breaking up a long sequence into batches, e.g. for model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def batch_it_crazy(\n",
    "    x,        # a time series as a PyTorch tensor, e.g. stereo or mono audio\n",
    "    win_len,  # length of each \"window\", i.e. length of each element in new batch\n",
    "    ):\n",
    "    \"(pun intended) Chop up long sequence into a batch of win_len windows\"\n",
    "    if len(x.shape) < 2: x = x.unsqueeze(0)  # guard against 1-d arrays\n",
    "    x_len = x.shape[-1]\n",
    "    n_windows = (x_len // win_len) + 1\n",
    "    pad_amt = win_len * n_windows - x_len  # pad end w. zeros to make lengths even when split\n",
    "    xpad = F.pad(x, (0, pad_amt))\n",
    "    return rearrange(xpad, 'd (b n) -> b d n', n=win_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `batch_it_crazy()` for stereo input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 2, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones([2,1000])  # stereo\n",
    "batch_it_crazy(x, 10).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and for mono: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 1, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones([1000])   # mono\n",
    "batch_it_crazy(x, 10).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and yeah, currently that \"` 1,`\" stays because other parts of the code(s) will be assuming \"multichannel\" audio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makedir \n",
    "The next routine creates a directory if it doesn't already exist.  We'll even let it take a \"nested\" directory such as `a/b/c/d` and the routine will create any directories in that string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def makedir(\n",
    "    path:str,              # directory or nested set of directories\n",
    "    ):\n",
    "    \"creates directories where they don't exist\"\n",
    "    if os.path.isdir(path): return  # don't make it if it already exists\n",
    "    #print(f\"  Making directory {path}\")\n",
    "    try:\n",
    "        os.makedirs(path)  # recursively make all dirs named in path\n",
    "    except:                # don't really care about errors\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_audio_filenames\n",
    "Often we'll want to grab a long list of audio filenames by looking through a directory and all its subdirectories.  We could use something like `glob`, `glob` turns out to be extremely slow when large numbers of files (say, more than 100,000) are involved.  Instead we will use the much faster `os.scandir()`, which was packaged nicely into the following routine in [an answer to a StackOverflow question](https://stackoverflow.com/a/59803793/4259243) from which this code is modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fast_scandir(\n",
    "    dir:str,  # top-level directory at which to begin scanning\n",
    "    ext:list  # list of allowed file extensions\n",
    "    ):\n",
    "    \"very fast `glob` alternative. from https://stackoverflow.com/a/59803793/4259243\"\n",
    "    subfolders, files = [], []\n",
    "    ext = ['.'+x if x[0]!='.' else x for x in ext]  # add starting period to extensions if needed\n",
    "    try: # hope to avoid 'permission denied' by this try\n",
    "        for f in os.scandir(dir):\n",
    "            try: # 'hope to avoid too many levels of symbolic links' error\n",
    "                if f.is_dir():\n",
    "                    subfolders.append(f.path)\n",
    "                elif f.is_file():\n",
    "                    if os.path.splitext(f.name)[1].lower() in ext:\n",
    "                        files.append(f.path)\n",
    "            except:\n",
    "                pass \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for dir in list(subfolders):\n",
    "        sf, f = fast_scandir(dir, ext)\n",
    "        subfolders.extend(sf)\n",
    "        files.extend(f)\n",
    "    return subfolders, files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\examples\\\\example.wav']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, files = fast_scandir('.', ['wav','flac','ogg','aiff','aif','mp3'])\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, rather than being given a single parent directory, we may be given a list of directories in which to look for files.  The following just called `fast_scandir()` for each of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_audio_filenames(\n",
    "    paths:list   # directories in which to search\n",
    "    ):\n",
    "    \"recursively get a list of audio filenames\"\n",
    "    filenames = []\n",
    "    if type(paths) is str: paths = [paths]\n",
    "    for path in paths:               # get a list of relevant filenames\n",
    "        subfolders, files = fast_scandir(path, ['.wav','.flac','.ogg','.aiff','.aif','.mp3'])\n",
    "        filenames.extend(files)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a fun trick to show off how fast this is: Run in the user's directory tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 audio files.\n"
     ]
    }
   ],
   "source": [
    "path = str(os.path.expanduser(\"~\"))+'/Downloads'\n",
    "if os.path.exists(path):\n",
    "    files = get_audio_filenames(path)\n",
    "    print(f\"Found {len(files)} audio files.\")\n",
    "else:\n",
    "    print(\"Ok it was just a thought.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pybit 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
