{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Routines for loading/handling datasets\n",
    "output-file: datasets.html\n",
    "title: datasets\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe09744",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9414fc4",
   "metadata": {},
   "source": [
    "Many of these routines are dupes or mods from \"audio-diffusion\" repo by Zach Evans w/ contributions by Scott Hawley https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79380ec",
   "metadata": {},
   "source": [
    "## Augmentation routines\n",
    "\n",
    "Not all of these are used.  Code copied from https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PadCrop\n",
       "\n",
       ">      PadCrop (n_samples, randomize=True, redraw_silence=True,\n",
       ">               silence_thresh=-60, max_redraws=2)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_samples |  |  | length of chunk to extract from longer signal |\n",
       "| randomize | bool | True | draw cropped chunk from a random position in audio file |\n",
       "| redraw_silence | bool | True | a chunk containing silence will be replaced with a new one |\n",
       "| silence_thresh | int | -60 | threshold in dB below which we declare to be silence |\n",
       "| max_redraws | int | 2 | when redrawing silences, don't do it more than this many |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L27){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PadCrop\n",
       "\n",
       ">      PadCrop (n_samples, randomize=True, redraw_silence=True,\n",
       ">               silence_thresh=-60, max_redraws=2)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_samples |  |  | length of chunk to extract from longer signal |\n",
       "| randomize | bool | True | draw cropped chunk from a random position in audio file |\n",
       "| redraw_silence | bool | True | a chunk containing silence will be replaced with a new one |\n",
       "| silence_thresh | int | -60 | threshold in dB below which we declare to be silence |\n",
       "| max_redraws | int | 2 | when redrawing silences, don't do it more than this many |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PadCrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PhaseFlipper\n",
       "\n",
       ">      PhaseFlipper (p=0.5)\n",
       "\n",
       "she was PHAAAAAAA-AAAASE FLIPPER, a random invert yeah\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| p | float | 0.5 | probability that phase flip will be applied |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PhaseFlipper\n",
       "\n",
       ">      PhaseFlipper (p=0.5)\n",
       "\n",
       "she was PHAAAAAAA-AAAASE FLIPPER, a random invert yeah\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| p | float | 0.5 | probability that phase flip will be applied |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(PhaseFlipper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FillTheNoise\n",
       "\n",
       ">      FillTheNoise (p=0.33)\n",
       "\n",
       "randomly adds a bit of noise, just to spice things up\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| p | float | 0.33 | probability that noise will be added |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L68){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FillTheNoise\n",
       "\n",
       ">      FillTheNoise (p=0.33)\n",
       "\n",
       "randomly adds a bit of noise, just to spice things up\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| p | float | 0.33 | probability that noise will be added |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(FillTheNoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L79){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RandPool\n",
       "\n",
       ">      RandPool (p=0.2)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L79){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RandPool\n",
       "\n",
       ">      RandPool (p=0.2)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(RandPool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NormInputs\n",
       "\n",
       ">      NormInputs (do_norm=True)\n",
       "\n",
       "Normalize inputs to [-1,1]. Useful for quiet inputs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| do_norm | bool | True | controllable parameter for turning normalization on/off |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NormInputs\n",
       "\n",
       ">      NormInputs (do_norm=True)\n",
       "\n",
       "Normalize inputs to [-1,1]. Useful for quiet inputs\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| do_norm | bool | True | controllable parameter for turning normalization on/off |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(NormInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Mono\n",
       "\n",
       ">      Mono ()\n",
       "\n",
       "convert audio to mono"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Mono\n",
       "\n",
       ">      Mono ()\n",
       "\n",
       "convert audio to mono"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Stereo\n",
       "\n",
       ">      Stereo ()\n",
       "\n",
       "convert audio to stereo"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Stereo\n",
       "\n",
       ">      Stereo ()\n",
       "\n",
       "convert audio to stereo"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Stereo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L124){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RandomGain\n",
       "\n",
       ">      RandomGain (min_gain, max_gain)\n",
       "\n",
       "apply a random gain to audio"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L124){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RandomGain\n",
       "\n",
       ">      RandomGain (min_gain, max_gain)\n",
       "\n",
       "apply a random gain to audio"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(RandomGain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68f216",
   "metadata": {},
   "source": [
    "## WebDataset support\n",
    "\n",
    "\n",
    "### Background Info\n",
    "Refer to the official [WebDataset Repo on GitHub](https://github.com/webdataset/webdataset).\n",
    "\n",
    "> WebDataset makes it easy to write I/O pipelines for large datasets. Datasets can be stored locally or in the cloud.\n",
    "\n",
    "They use the word \"shards\" but never define what \"shard\" means.  I (S.H.) surmise they mean the groups of data files which are gathered into a series of `.tar` files -- the `.tar` files are the shards? \n",
    "\n",
    "cf. Video Tutorial: [\"Loading Training Data with WebDataset\"](https://www.youtube.com/watch?v=mTv_ePYeBhs).\n",
    "\n",
    "The recommended usage for AWS S3 can be seen in [this GitHub Issue comment by tmbdev] (https://github.com/webdataset/webdataset/issues/21#issuecomment-706008342): \n",
    "\n",
    "```Python\n",
    "url = \"pipe:s3cmd get s3://bucket/dataset-{000000..000999}.tar -\"\n",
    "dataset = wds.Dataset(url)...\n",
    "```\n",
    "> ^[sic.] `s3cmd get` should read `aws s3 cp`. \n",
    "\n",
    "That URL is expecting a contiguously-numbered range of .tar files. So if the file numbers are contiguous (no gaps), then we'll have an easy time. Otherwise, there are ways to pass in a long list of similar \"pipe:...tar\" 'urls' for each and every tar file, which is still not a big deal though it may appear messier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de14168",
   "metadata": {},
   "source": [
    "### General utility: `get_s3_contents()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L137){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_s3_contents\n",
       "\n",
       ">      get_s3_contents (dataset_path, s3_url_prefix='s3://s-laion-\n",
       ">                       audio/webdataset_tar', filter='')\n",
       "\n",
       "Gets a list of names of files or subdirectories on an s3 path"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L137){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_s3_contents\n",
       "\n",
       ">      get_s3_contents (dataset_path, s3_url_prefix='s3://s-laion-\n",
       ">                       audio/webdataset_tar', filter='')\n",
       "\n",
       "Gets a list of names of files or subdirectories on an s3 path"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_s3_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde32e18",
   "metadata": {},
   "source": [
    "Let's test that on the FSD50K dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1e399",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'valid']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_s3_contents('FSD50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9724af",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.tar',\n",
       " '1.tar',\n",
       " '10.tar',\n",
       " '11.tar',\n",
       " '12.tar',\n",
       " '13.tar',\n",
       " '14.tar',\n",
       " '15.tar',\n",
       " '16.tar',\n",
       " '17.tar',\n",
       " '18.tar',\n",
       " '19.tar',\n",
       " '2.tar',\n",
       " '3.tar',\n",
       " '4.tar',\n",
       " '5.tar',\n",
       " '6.tar',\n",
       " '7.tar',\n",
       " '8.tar',\n",
       " '9.tar',\n",
       " 'sizes.json']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_s3_contents('FSD50K/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652b014",
   "metadata": {},
   "source": [
    "And let's try filtering for only tar files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b794212",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.tar',\n",
       " '1.tar',\n",
       " '10.tar',\n",
       " '11.tar',\n",
       " '12.tar',\n",
       " '13.tar',\n",
       " '14.tar',\n",
       " '15.tar',\n",
       " '16.tar',\n",
       " '17.tar',\n",
       " '18.tar',\n",
       " '19.tar',\n",
       " '2.tar',\n",
       " '3.tar',\n",
       " '4.tar',\n",
       " '5.tar',\n",
       " '6.tar',\n",
       " '7.tar',\n",
       " '8.tar',\n",
       " '9.tar']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "tar_names = get_s3_contents('FSD50K/test', filter='tar')\n",
    "tar_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9a03d",
   "metadata": {},
   "source": [
    "### For contiguous file-number lists...\n",
    "\n",
    "Maybe the range of tar numbers is contigous. If so, let's have something to output that range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L146){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_contiguous_range\n",
       "\n",
       ">      get_contiguous_range (tar_names)\n",
       "\n",
       "given a string of tar file names, return a string of their range if the numbers are contiguous. Otherwise return empty string\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| tar_names | list of tar file names, although the .tar part is actually optional |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L146){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_contiguous_range\n",
       "\n",
       ">      get_contiguous_range (tar_names)\n",
       "\n",
       "given a string of tar file names, return a string of their range if the numbers are contiguous. Otherwise return empty string\n",
       "\n",
       "|    | **Details** |\n",
       "| -- | ----------- |\n",
       "| tar_names | list of tar file names, although the .tar part is actually optional |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_contiguous_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40b720",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{0..19}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "cont_range = get_contiguous_range(tar_names)\n",
    "cont_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08f2f5",
   "metadata": {},
   "source": [
    "Test if leading zeros are preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76f5f4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{00000..000019}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "get_contiguous_range(['0000'+x for x in tar_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3158e11",
   "metadata": {},
   "source": [
    "Test zero-element and single element versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f0267",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(get_contiguous_range([]))\n",
    "print(get_contiguous_range([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309f2e5",
   "metadata": {},
   "source": [
    "And show that '.tar' is optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632e08d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{01..3}'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_contiguous_range(['01','02','3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b55148",
   "metadata": {},
   "source": [
    "....So, if a contiguous range of tar file names is available in a WebDataset directory, then we can just use the native WebDataset creation utilities and can ignore all the other %$#*& that's about to follow below. \n",
    "\n",
    "Let's test the simple version first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d20707",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe:aws s3 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/{0..19}.tar -\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "s3_url_prefix='s3://s-laion-audio/webdataset_tar/'\n",
    "url = f\"pipe:aws s3 cp {s3_url_prefix}FSD50K/test/{cont_range}.tar -\"  # 'aws get' is not a thing. 'aws cp' is\n",
    "print(url)\n",
    "dataset = wds.WebDataset(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aef619",
   "metadata": {},
   "source": [
    "Hooray, it didn't crash! \n",
    "\n",
    "Try dataloader-ing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330f703",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "## NOTE TO SELF: DON'T RUN THIS ON STABILITY CLUSTER HEADNODE\n",
    "if 'this next part fails' == 'darn it':\n",
    "    loader = wds.WebLoader(dataset, num_workers=4, batch_size=8)\n",
    "    #loader = loader.batched(12)\n",
    "    batch = next(iter(loader))\n",
    "    batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0b432",
   "metadata": {},
   "source": [
    "### Non-contiguously-numbered lists of tar files...\n",
    "Because you could do a test-train-val split by moving the tar files around.\n",
    "this is what all the extra code is for.\n",
    "\n",
    "A lot of the code predating this was written by LAION who require that the `.json` file(s) for the webdataset(s) be downloaded first. So, let's write a utility for that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L163){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### download_webdataset_json\n",
       "\n",
       ">      download_webdataset_json (datasetnames, dataset_split={},\n",
       ">                                src_prefix='s3://s-laion-audio/webdataset_tar',\n",
       ">                                dst_prefix='./json_files', force=False)\n",
       "\n",
       "Downloads the json info of webdataset (sub-)file sizes\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| datasetnames |  |  | list of names of valid AudioDataset datasets / paths |\n",
       "| dataset_split | dict | {} | keys are dataset names, values are lists of subdirs |\n",
       "| src_prefix | str | s3://s-laion-audio/webdataset_tar | parent location where the dataset lives |\n",
       "| dst_prefix | str | ./json_files | local path to save the json |\n",
       "| force | bool | False | Force new download even if local copy exists |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L163){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### download_webdataset_json\n",
       "\n",
       ">      download_webdataset_json (datasetnames, dataset_split={},\n",
       ">                                src_prefix='s3://s-laion-audio/webdataset_tar',\n",
       ">                                dst_prefix='./json_files', force=False)\n",
       "\n",
       "Downloads the json info of webdataset (sub-)file sizes\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| datasetnames |  |  | list of names of valid AudioDataset datasets / paths |\n",
       "| dataset_split | dict | {} | keys are dataset names, values are lists of subdirs |\n",
       "| src_prefix | str | s3://s-laion-audio/webdataset_tar | parent location where the dataset lives |\n",
       "| dst_prefix | str | ./json_files | local path to save the json |\n",
       "| force | bool | False | Force new download even if local copy exists |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(download_webdataset_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcf904",
   "metadata": {},
   "source": [
    "test get_webdataset_json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff394f6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/test/sizes.json to json_files/FSD50K/test/sizes.json\n",
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/train/sizes.json to json_files/FSD50K/train/sizes.json\n",
      "download: s3://s-laion-audio/webdataset_tar/FSD50K/valid/sizes.json to json_files/FSD50K/valid/sizes.json\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "from types import SimpleNamespace\n",
    "args = SimpleNamespace(remotedata=True, datasetnames=['FSD50K'],\n",
    "                       dataset_type=\"webdataset\",\n",
    "                       dataset_proportion=1, datasetpath='IDK')\n",
    "download_webdataset_json(args.datasetnames, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7510206",
   "metadata": {},
   "source": [
    "For non-contiguous files, we need a list of urls to every single tar file individually.  That's what this next code from LAION's CLAP repo does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a2c08",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def get_tar_path_s3(base_s3_path:str, \n",
    "    train_valid_test:list[str], \n",
    "    dataset_names:list[str]=[''], \n",
    "    cache_path:str='', \n",
    "    recache:bool=False,\n",
    "    ):\n",
    "    \"Code from LAOIN CLAP may not keep. This spits out a list of aws cli calls to download every tar file\"\n",
    "    if os.path.isfile(cache_path) and not recache:\n",
    "        with open(cache_path) as f:\n",
    "            print(\"Loading Cache\")\n",
    "            return json.load(f)\n",
    "\n",
    "    # create cmd for collecting url spesific dataset, \n",
    "    # if `dataset_names` is not given it will search the full base_s3_path\n",
    "    cmds = [f'aws s3 ls s3://{os.path.join(base_s3_path, name, \"\")} --recursive | grep /.*.tar' for name in dataset_names]\n",
    "    # urls are collected\n",
    "    urls = [os.popen(cmd).read() for cmd in cmds]\n",
    "    # cleaning the urls to conform with webdataset\n",
    "    final_urls = [i.split(' ')[-1] for url in urls for i in url.split('\\n')]\n",
    "    final_urls = [f'pipe:aws s3 --cli-connect-timeout 0 cp s3://{os.path.join(base_s3_path, *i.split(\"/\")[1:])} -' for i in final_urls]\n",
    "    # Spliting url by state e.g. train, test and valud\n",
    "    final_urls = {state:[url for url in final_urls if state in url] for state in train_valid_test}\n",
    "\n",
    "    if cache_path:\n",
    "        with open(cache_path, 'w') as f:\n",
    "            json.dump(final_urls, f)\n",
    "\n",
    "    return final_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1785ed",
   "metadata": {},
   "source": [
    "Let's grab every tar file in the entire FSD50K dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfbe1cd",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urls = {'test': ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -'], 'valid': ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "urls = get_tar_path_s3('s-laion-audio/webdataset_tar',['test', 'valid'], dataset_names=['FSD50K'])\n",
    "print(\"urls =\",urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ceb32",
   "metadata": {},
   "source": [
    "Another version that acheives the same effect: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df110421",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def get_tar_path_from_dataset_name(\n",
    "    dataset_names, dataset_types, islocal,  dataset_path, proportion=1, ):\n",
    "    \"\"\"\n",
    "    From LAOIN\n",
    "    Get tar path from dataset name and type\n",
    "    \"\"\"\n",
    "    if islocal:\n",
    "        output = []\n",
    "        for n in dataset_names:\n",
    "            for s in dataset_types:\n",
    "                tmp = []\n",
    "                sizefilepath_ = f\"./json_files/{n}/{s}/sizes.json\" #  TODO:!!!\n",
    "                if not os.path.exists(sizefilepath_):\n",
    "                    continue\n",
    "                sizes = json.load(open(sizefilepath_, \"r\"))\n",
    "                for k in sizes.keys():\n",
    "                    tmp.append(\n",
    "                        f\"{dataset_path}/{n}/{s}/{k}\"\n",
    "                    )\n",
    "                if proportion!=1:\n",
    "                    tmp = random.sample(tmp, int(proportion * len(tmp)))\n",
    "                output.append(tmp)\n",
    "        return sum(output, [])\n",
    "    else:\n",
    "\n",
    "        output = []\n",
    "        for n in dataset_names:\n",
    "            for s in dataset_types:\n",
    "                tmp = []\n",
    "                sizefilepath_ = f\"./json_files/{n}/{s}/sizes.json\"\n",
    "                if not os.path.exists(sizefilepath_):\n",
    "                    continue\n",
    "                sizes = json.load(open(sizefilepath_, \"r\"))\n",
    "                for k in sizes.keys():\n",
    "                    tmp.append(\n",
    "                        f\"pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/{n}/{s}/{k} -\"\n",
    "                    )\n",
    "                    # TODO: add dataset_path to remote dataset in the future.\n",
    "                if proportion!=1:\n",
    "                    tmp = random.sample(tmp, int(proportion * len(tmp)))\n",
    "                output.append(tmp)\n",
    "                print(\"output= \",output)\n",
    "        return sum(output, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397a165",
   "metadata": {},
   "source": [
    "Test ^that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a016dc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output=  [['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -']]\n",
      "output=  [['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -'], ['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -', 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/0.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/1.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/2.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/3.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/4.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/5.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/6.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/7.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/8.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/9.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/10.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/11.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/12.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/13.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/14.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/15.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/16.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/17.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/18.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/test/19.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/0.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/1.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/2.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/3.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/4.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/5.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/6.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/7.tar -',\n",
       " 'pipe:aws s3 --cli-connect-timeout 0 cp s3://s-laion-audio/webdataset_tar/FSD50K/valid/8.tar -']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "train_data_tar_path = get_tar_path_from_dataset_name(\n",
    "    ['FSD50K'],\n",
    "    ['test','valid'],\n",
    "    islocal=False,\n",
    "    proportion=1.0,\n",
    "    dataset_path='/fsx/shawley/data/webdataset',\n",
    ")\n",
    "train_data_tar_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb85d78",
   "metadata": {},
   "source": [
    "And now a massive data-pipelining example from LAION that will definitely get modified for this repo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L196){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_wds_dataset\n",
       "\n",
       ">      get_wds_dataset (args, model_cfg, is_train, audio_ext='flac',\n",
       ">                       text_ext='json', max_len=480000, proportion=1.0,\n",
       ">                       sizefilepath_=None, is_local=None)\n",
       "\n",
       "Get a dataset for wdsdataloader."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L196){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_wds_dataset\n",
       "\n",
       ">      get_wds_dataset (args, model_cfg, is_train, audio_ext='flac',\n",
       ">                       text_ext='json', max_len=480000, proportion=1.0,\n",
       ">                       sizefilepath_=None, is_local=None)\n",
       "\n",
       "Get a dataset for wdsdataloader."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(get_wds_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataInfo\n",
       "\n",
       ">      DataInfo (dataloader:DataLoader, sampler:DistributedSampler)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataInfo\n",
       "\n",
       ">      DataInfo (dataloader:DataLoader, sampler:DistributedSampler)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(DataInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f4b026",
   "metadata": {},
   "source": [
    ".....yeah no tests for that yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3003418c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# LAION cut n paste\n",
    "if 'doesnt work yet' == 'stand by':\n",
    "    train_data = get_wds_dataset(    args,\n",
    "        model_cfg,\n",
    "        is_train,\n",
    "        audio_ext=\"flac\",\n",
    "        text_ext=\"json\",\n",
    "        max_len=480000,\n",
    "        proportion=1.0,\n",
    "        sizefilepath_=None,\n",
    "        is_local=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf846139",
   "metadata": {},
   "source": [
    "# AudioDataset class\n",
    "\n",
    "The flagship class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AudioDataset\n",
       "\n",
       ">      AudioDataset (*args, **kwds)\n",
       "\n",
       "Reads from a tree of directories and serves up cropped bits from any and all audio files\n",
       "found therein. For efficiency, best if you \"chunk\" these files via chunkadelic\n",
       "modified from https://github.com/drscotthawley/audio-diffusion/blob/main/dataset/dataset.py"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/drscotthawley/aeiou/blob/main/aeiou/datasets.py#L345){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### AudioDataset\n",
       "\n",
       ">      AudioDataset (*args, **kwds)\n",
       "\n",
       "Reads from a tree of directories and serves up cropped bits from any and all audio files\n",
       "found therein. For efficiency, best if you \"chunk\" these files via chunkadelic\n",
       "modified from https://github.com/drscotthawley/audio-diffusion/blob/main/dataset/dataset.py"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(AudioDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91122ae6",
   "metadata": {},
   "source": [
    "Quick check to catch minor errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c2f993",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dataset = AudioDataset('examples/', augs='Stereo(), PhaseFlipper(), FillTheNoise(), NormInputs()')\n",
    "signal = dataset.__getitem__(0)\n",
    "print(\"signal.shape =\",signal.shape)\n",
    "\n",
    "print(\"\\nStereo -------------\")\n",
    "dataset2 = AudioDataset('examples/', augs='Stereo(), PhaseFlipper()')\n",
    "signal2 = dataset2.__getitem__(0)\n",
    "print(\"signal2.shape =\",signal2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8b622",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
