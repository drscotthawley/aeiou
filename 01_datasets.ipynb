{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe09744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9414fc4",
   "metadata": {},
   "source": [
    "# datasets\n",
    "> Routines for loading/handling datasets\n",
    "\n",
    "Many of these routines are dupes or mods from \"audio-diffusion\" repo by Zach Evans w/ contributions by Scott Hawley https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a097942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shawley/envs/aeiou/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from torchaudio import transforms as T\n",
    "import random\n",
    "import os\n",
    "import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from aeiou.core import load_audio, get_audio_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79380ec",
   "metadata": {},
   "source": [
    "## Augmentation routines\n",
    "\n",
    "Not all of these are used.  Code copied from https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PadCrop(nn.Module):\n",
    "    def __init__(self, n_samples, randomize=True):\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.randomize = randomize\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        n, s = signal.shape\n",
    "        start = 0 if (not self.randomize) else torch.randint(0, max(0, s - self.n_samples) + 1, []).item()\n",
    "        end = start + self.n_samples\n",
    "        output = signal.new_zeros([n, self.n_samples])\n",
    "        output[:, :min(s, self.n_samples)] = signal[:, start:end]\n",
    "        return output\n",
    "\n",
    "    \n",
    "class PhaseFlipper(nn.Module):\n",
    "    \"she was PHAAAAAAA-AAAASE FLIPPER, a random invert yeah\"\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return -signal if (random.random() < self.p) else signal\n",
    "\n",
    "\n",
    "class FillTheNoise(nn.Module):\n",
    "    \"randomly adds a bit of noise, just to spice things up\"\n",
    "    def __init__(self, p=0.33):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return signal + 0.25*random.random()*(2*torch.rand_like(signal)-1) if (random.random() < self.p) else signal\n",
    "\n",
    "    \n",
    "class RandPool(nn.Module):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p, self.maxkern = p, 100\n",
    "    def __call__(self, signal):\n",
    "        if (random.random() < self.p):\n",
    "            ksize = int(random.random()*self.maxkern)\n",
    "            avger = nn.AvgPool1d(kernel_size=ksize, stride=1, padding=1)\n",
    "            return avger(signal)\n",
    "        else:\n",
    "            return signal\n",
    "        \n",
    "\n",
    "class NormInputs(nn.Module):\n",
    "    \"useful for quiet inputs. intended to be part of augmentation chain; not activated by default\"\n",
    "    def __init__(self, do_norm=False):\n",
    "        super().__init__()\n",
    "        self.do_norm = do_norm\n",
    "        self.eps = 1e-2\n",
    "    def __call__(self, signal):\n",
    "        return signal if (not self.do_norm) else signal/(torch.amax(signal,-1)[0] + self.eps)\n",
    "\n",
    "    \n",
    "class Mono(nn.Module):\n",
    "    def __call__(self, signal):\n",
    "        return torch.mean(signal, dim=0) if len(signal.shape) > 1 else signal\n",
    "\n",
    "\n",
    "class Stereo(nn.Module):\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        signal_shape = signal.shape\n",
    "        # Check if it's mono\n",
    "        if len(signal_shape) == 1: # s -> 2, s\n",
    "            signal = signal.unsqueeze(0).repeat(2, 1)\n",
    "        elif len(signal_shape) == 2:\n",
    "            if signal_shape[0] == 1: #1, s -> 2, s\n",
    "                signal = signal.repeat(2, 1)\n",
    "            elif signal_shape[0] > 2: #?, s -> 2,s\n",
    "                signal = signal[:2, :]    \n",
    "        return signal\n",
    "\n",
    "    \n",
    "class RandomGain(nn.Module):\n",
    "    def __init__(self, min_gain, max_gain):\n",
    "        super().__init__()\n",
    "        self.min_gain = min_gain\n",
    "        self.max_gain = max_gain\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        gain = random.uniform(self.min_gain, self.max_gain)\n",
    "        signal = signal * gain\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf846139",
   "metadata": {},
   "source": [
    "## AudioDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba890cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "  \"\"\"\n",
    "  Reads from a tree of directories and serves up cropped bits from any and all audio files\n",
    "  found therein. For efficiency, best if you \"chunk\" these files via chunkadelic\n",
    "  modified from https://github.com/drscotthawley/audio-diffusion/blob/main/dataset/dataset.py\n",
    "  \"\"\"\n",
    "  def __init__(self, paths, global_args):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.augs = torch.nn.Sequential(\n",
    "      PadCrop(global_args.sample_size, randomize=global_args.random_crop),\n",
    "      #RandomGain(0.7, 1.0),\n",
    "      #NormInputs(do_norm=global_args.norm_inputs),\n",
    "      #OneMinus(), # this is crazy, reverse the signal rel. to +/-1\n",
    "      #RandPool(),\n",
    "      #FillTheNoise(),\n",
    "      PhaseFlipper(),\n",
    "      #NormInputs(do_norm=global_args.norm_inputs),\n",
    "    )\n",
    "\n",
    "    self.encoding = torch.nn.Sequential(\n",
    "      Stereo()\n",
    "    )\n",
    "\n",
    "    self.filenames = get_audio_filenames()\n",
    "\n",
    "    self.sr = global_args.sample_rate\n",
    "    if hasattr(global_args,'load_frac'):\n",
    "      self.load_frac = global_args.load_frac\n",
    "    else:\n",
    "      self.load_frac = 1.0\n",
    "    self.n_files = int(len(self.filenames)*self.load_frac)\n",
    "    self.filenames = self.filenames[0:self.n_files]\n",
    "\n",
    "    self.num_gpus = global_args.num_gpus\n",
    "\n",
    "    self.cache_training_data = global_args.cache_training_data\n",
    "\n",
    "    if self.cache_training_data: self.preload_files()\n",
    "\n",
    "\n",
    "  def load_file_ind(self, file_list,i): # used when caching training data\n",
    "    return load_audio(file_list[i]).cpu()\n",
    "\n",
    "  def get_data_range(self): # for parallel runs, only grab part of the data\n",
    "    start, stop = 0, len(self.filenames)\n",
    "    try:\n",
    "      local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "      world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "      interval = stop//world_size\n",
    "      start, stop = local_rank*interval, (local_rank+1)*interval\n",
    "      #print(\"local_rank, world_size, start, stop =\",local_rank, world_size, start, stop)\n",
    "      return start, stop\n",
    "      #rank = os.environ[\"RANK\"]\n",
    "    except KeyError as e: # we're on GPU 0 and the others haven't been initialized yet\n",
    "      start, stop = 0, len(self.filenames)//self.num_gpus\n",
    "      return start, stop\n",
    "\n",
    "  def preload_files(self):\n",
    "      print(f\"Caching {self.n_files} input audio files:\")\n",
    "      wrapper = partial(self.load_file_ind, self.filenames)\n",
    "      start, stop = self.get_data_range()\n",
    "      with Pool(processes=cpu_count()) as p:   # //8 to avoid FS bottleneck and/or too many processes (b/c * num_gpus)\n",
    "        self.audio_files = list(tqdm.tqdm(p.imap(wrapper, range(start,stop)), total=stop-start))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.filenames)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    audio_filename = self.filenames[idx]\n",
    "    try:\n",
    "      if self.cache_training_data:\n",
    "        audio = self.audio_files[idx] # .copy()\n",
    "      else:\n",
    "        audio = self.load_file(audio_filename)\n",
    "\n",
    "      #Run augmentations on this sample (including random crop)\n",
    "      if self.augs is not None:\n",
    "        audio = self.augs(audio)\n",
    "\n",
    "      audio = audio.clamp(-1, 1)\n",
    "\n",
    "      #Encode the file to assist in prediction\n",
    "      if self.encoding is not None:\n",
    "        audio = self.encoding(audio)\n",
    "\n",
    "      return (audio, audio_filename)\n",
    "    except Exception as e:\n",
    "     # print(f'Couldn\\'t load file {audio_filename}: {e}')\n",
    "      return self[random.randrange(len(self))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5099c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
